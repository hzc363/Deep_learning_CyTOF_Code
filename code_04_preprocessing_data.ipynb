{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from rpy2.robjects import pandas2ri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### load data #####\n",
    "expr_list = pickle.load( open( \"result_03_sampled_data.obj\", \"rb\" ) )\n",
    "cytof_files = pd.read_csv(\"result_01_cytof_file_info.csv\")\n",
    "print(len(expr_list))\n",
    "print(cytof_files .shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### only include CMV data and HAI_28 data #####\n",
    "a = [t1==t1 for t1 in cytof_files.CMV_Ab] \n",
    "b = [t1==t1 for t1 in cytof_files.HAI_28]\n",
    "r1 = [a[i]|b[i] for i in range(len(a))]\n",
    "\n",
    "cytof_files = cytof_files.loc[r1,:]\n",
    "expr_list = [expr_list[i] for i in range(len(expr_list)) if r1[i]==True]\n",
    "\n",
    "print(len(expr_list))\n",
    "print(cytof_files.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### look at markers #####\n",
    "old_markers = []\n",
    "for i in range(0,len(expr_list)):\n",
    "    expr_list[i].colnames = [re.sub(\"\\\\(.*\", \"\", t1).upper() for t1 in expr_list[i].colnames]\n",
    "    old_markers = old_markers + list(expr_list[i].colnames)\n",
    "old_markers = list(set(old_markers))\n",
    "old_markers.sort()\n",
    "print(old_markers[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### standardize markers #####\n",
    "marker_dict = {\n",
    "    '':\"NA\",\n",
    " 'BA138DI':\"NA\",\n",
    " 'CD45_ACUTE':\"CD45\",\n",
    " 'CD45_CONV':\"CD45\",\n",
    " 'CE140DI':\"NA\",\n",
    " 'CE142DI':\"NA\",\n",
    " 'CHIKV':'CHIKV',\n",
    " 'CS133DI':\"NA\",\n",
    " 'DEAD':'VIABILITY',\n",
    " 'DNA1':\"DNA1\",\n",
    " 'DNA2':\"DNA2\",\n",
    " 'EVENT_LENGTH':\"CELL_LENGTH\",\n",
    " 'LU176DI':\"NA\",\n",
    " 'OS189DI':\"NA\",\n",
    " 'PD-1':\"PD1\",\n",
    " 'PR141DI':\"NA\",\n",
    " 'PT195DI':\"NA\",\n",
    " 'XE131DI':\"NA\"\n",
    "}\n",
    "\n",
    "for i in range(0,len(expr_list)):\n",
    "    for j in range(0,len(expr_list[i].colnames)):\n",
    "        if expr_list[i].colnames[j] in list(marker_dict.keys()):\n",
    "            expr_list[i].colnames[j] = marker_dict[expr_list[i].colnames[j]]\n",
    "            \n",
    "##### look at standarized markers #####\n",
    "new_markers = []\n",
    "for i in range(0,len(expr_list)):\n",
    "    expr_list[i].colnames = [re.sub(\"\\\\(.*\", \"\", t1).upper() for t1 in expr_list[i].colnames]\n",
    "    new_markers = new_markers + list(expr_list[i].colnames)\n",
    "new_markers = pd.DataFrame({'markers':new_markers})\n",
    "\n",
    "new_markers = (new_markers.groupby(['markers']).size().reset_index(name='counts').\n",
    "               sort_values(by=['counts','markers'],ascending=False))\n",
    "\n",
    "\n",
    "print(new_markers.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### get unified data #####\n",
    "selected_markers = list(new_markers.loc[new_markers.counts>=532,\"markers\"])\n",
    "print(selected_markers)\n",
    "\n",
    "for i in range(0,len(expr_list)):\n",
    "    t1 = expr_list[i] \n",
    "    t1 = pandas2ri.ri2py(t1)\n",
    "    expr_list[i] = t1.loc[:,selected_markers]\n",
    "\n",
    "\n",
    "print(cytof_files.shape)\n",
    "p1 = list(set([expr_list[i].shape for i in range(len(expr_list))]))\n",
    "print(len(expr_list))\n",
    "print(p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### define function for adding interactions #####\n",
    "def interactions( df ):\n",
    "    df_new = df\n",
    "    for i in range(df.shape[1]):\n",
    "        for j in range((i+1),df.shape[1]):\n",
    "            cn = df.columns[i]+\"_\"+df.columns[j]\n",
    "            df2 = pd.DataFrame({cn:(df.iloc[:,i]*df.iloc[:,j])})\n",
    "            df_new = pd.concat([df_new,df2.reset_index(drop=True)], axis=1)\n",
    "    return df_new\n",
    "\n",
    "def arcsinh(x):\n",
    "    return(np.arcsinh(x/5))\n",
    "\n",
    "def scale(x):\n",
    "    return((x-np.mean(x))/np.std(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coln = expr_list[0].columns.drop(\"TIME\")\n",
    "for i in range(len(expr_list)):\n",
    "    t1 = expr_list[i].drop(columns=\"TIME\")\n",
    "    t1 = t1.apply(arcsinh)#.apply(scale)\n",
    "    t1 = t1.values\n",
    "    #t1 = interactions(t1)\n",
    "    #t1 = t1.rank(pct=True).values\n",
    "    shape1 = list(t1.shape)+[1]\n",
    "    t1 = t1.reshape(shape1)\n",
    "    expr_list[i] = t1\n",
    "    \n",
    "expr_list = np.stack(expr_list)\n",
    "print(expr_list.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expr_df = expr_list.reshape(expr_list.shape[0:3])\n",
    "expr_df = expr_df[cytof_files.study_accession==\"SDY519\"]\n",
    "print(expr_df.shape)\n",
    "expr_df = expr_list.reshape([expr_list.shape[0]*expr_list.shape[1],\n",
    "                             expr_list.shape[2]])\n",
    "expr_df = pd.DataFrame(expr_df)\n",
    "expr_df.columns = coln\n",
    "print(expr_df.shape)\n",
    "display(expr_df.head())\n",
    "expr_df = expr_df.sample(n = 30000)\n",
    "expr_df.to_csv(\"Result_04_SDY519_expr.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = {\"cytof_files\":cytof_files, \n",
    "                  \"expr_list\" : expr_list,\n",
    "                 \"marker_names\" : coln}\n",
    "\n",
    "with open(\"result_04_processed_data_no_scale.obj\", \"wb\") as f:\n",
    "    pickle.dump(processed_data, f)\n",
    "    \n",
    "cytof_files.to_csv(\"result_04_cytof_files.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CyTOF_DL",
   "language": "python",
   "name": "cytof_dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
