{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, BatchNormalization, Activation, Concatenate\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, Input\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import random\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import keras.callbacks\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn import datasets, linear_model\n",
    "import seaborn as sns\n",
    "from numpy.random import seed; seed(111)\n",
    "from tensorflow import set_random_seed; set_random_seed(111)\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "from scipy.stats import kruskal\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### load data #####\n",
    "processed_data = pickle.load( open( \"result_04_processed_data_no_scale.obj\", \"rb\" ) )\n",
    "cytof_files = processed_data[\"cytof_files\"]\n",
    "expr_list = processed_data[\"expr_list\"]\n",
    "\n",
    "r1 = [t1==t1 for t1 in cytof_files.CMV_Ab] \n",
    "w1 = (cytof_files.isna().sum(axis=1).values)>=0\n",
    "\n",
    "cytof_files = cytof_files.loc[r1&w1,:]\n",
    "expr_list = expr_list[r1&w1]\n",
    "print(expr_list.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get demo and cytokine data\n",
    "col = ['gender', 'race', 'age', \n",
    "       'CCL11', 'CCL2', 'CCL3',\n",
    "       'CCL4', 'CCL5', 'CCL7', 'CD40LG', 'CSF1', 'CSF2', 'CSF3', 'CXCL1',\n",
    "       'CXCL10', 'CXCL5', 'CXCL8', 'FASLG', 'FGF2', 'HGF', 'ICAM1', 'IFN1@',\n",
    "       'IFNB1', 'IFNG', 'IL10', 'IL12', 'IL12B', 'IL13', 'IL15', 'IL17F',\n",
    "       'IL1A', 'IL1B', 'IL1R1', 'IL2', 'IL4', 'IL5', 'IL6', 'IL7', 'KITLG',\n",
    "       'LEP', 'LIF', 'LTA', 'NGF', 'PDGFB', 'RETN', 'SERPINE1', 'TGFA',\n",
    "       'TGFB1', 'TNF', 'TNFSF10', 'VCAM1', 'VEGFA']\n",
    "col = ['gender', 'race', 'age']\n",
    "x2 = cytof_files.loc[:,col]\n",
    "x2 = pd.get_dummies(x2, prefix=['gender', 'race'],drop_first=True)\n",
    "x2 = x2[[\"age\",\"gender_Male\",\"race_Asian\",\"race_Black or African American\",\"race_White\"]]\n",
    "\n",
    "norm_fun = (lambda x: (x - x.mean()) / x.std())\n",
    "x2 = x2.transform(norm_fun)\n",
    "\n",
    "x2 = x2.dropna(axis='columns')\n",
    "display(x2.head())\n",
    "x2 = x2.values\n",
    "\n",
    "y = cytof_files.CMV_Ab.values> 2\n",
    "\n",
    "x = expr_list\n",
    "x_shape = x.shape\n",
    "print(x_shape)\n",
    "x = x.reshape((x_shape[0]*x_shape[1],x_shape[2],x_shape[3]))\n",
    "x = np.apply_along_axis(norm_fun, 0, x)\n",
    "x = x.reshape(x_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### split train, validation and test######\n",
    "train_id = [i for i in range(len(x)) if cytof_files.study_accession.iloc[i] not in [\"SDY515\",\"SDY519\"]]\n",
    "valid_id = [i for i in range(len(x)) if cytof_files.study_accession.iloc[i]==\"SDY515\"]\n",
    "test_id = [i for i in range(len(x)) if cytof_files.study_accession.iloc[i]==\"SDY519\"]\n",
    "\n",
    "x_train = x[train_id]\n",
    "x_valid = x[valid_id]\n",
    "x_test = x[test_id]\n",
    "\n",
    "x2_train = x2[train_id]\n",
    "x2_valid = x2[valid_id]\n",
    "x2_test = x2[test_id]\n",
    "\n",
    "y_train = y[train_id]\n",
    "y_valid = y[valid_id]\n",
    "y_test = y[test_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##### define model #####\n",
    "left_input = Input(shape=x_train[0].shape)\n",
    "\n",
    "left_branch = Conv2D(3, kernel_size=(1, x_train.shape[2]),\n",
    "                 activation=None)(left_input)\n",
    "left_branch = BatchNormalization()(left_branch)\n",
    "left_branch = Activation(\"relu\")(left_branch)\n",
    "\n",
    "left_branch = Conv2D(3, (1, 1), activation=None)(left_branch)\n",
    "left_branch = BatchNormalization()(left_branch)\n",
    "left_branch = Activation(\"relu\")(left_branch)\n",
    "\n",
    "left_branch = AveragePooling2D(pool_size=(x_train.shape[1], 1))(left_branch)\n",
    "left_branch = Flatten()(left_branch)\n",
    "\n",
    "\n",
    "right_input = Input(shape=x2[0].shape)\n",
    "right_branch = Dense(1, activation=None)(right_input)\n",
    "right_branch = BatchNormalization()(right_branch)\n",
    "right_branch = Activation(\"relu\")(right_branch)\n",
    " \n",
    "merged = Concatenate()([left_branch, right_branch])\n",
    "merged = Dense(3, activation=None)(merged)\n",
    "merged = BatchNormalization()(merged)\n",
    "merged = Activation(\"relu\")(merged)\n",
    "merged = Dense(1, activation=\"sigmoid\")(merged)\n",
    "model = keras.models.Model(inputs=[left_input, right_input],\n",
    "                           outputs=merged)\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=keras.optimizers.Adam(lr=0.0001),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "checkpointer = keras.callbacks.ModelCheckpoint(filepath='result_09_weights.hdf5', monitor='val_loss', \n",
    "                                               verbose=0, save_best_only=True)\n",
    "earlyStop = keras.callbacks.EarlyStopping(monitor='loss', min_delta=0.00000001, patience=100, \n",
    "                                          verbose=0, mode='auto', baseline=None, restore_best_weights=True)\n",
    "\n",
    "model.fit([x_train,x2_train], y_train,\n",
    "          batch_size=30,\n",
    "          epochs=10000,\n",
    "          verbose=1,\n",
    "          callbacks=[checkpointer,earlyStop],\n",
    "          validation_data=([x_valid, x2_valid], y_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot train and validation loss\n",
    "plt.plot(model.history.history['loss'])\n",
    "plt.plot(model.history.history['val_loss'])\n",
    "plt.title('model train vs validation loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(model.history.history['acc'])\n",
    "plt.plot(model.history.history['val_acc'])\n",
    "plt.title('model train vs validation accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "best_model = load_model('result_09_weights.hdf5')\n",
    "\n",
    "# print result of the best model\n",
    "score = best_model.evaluate([x_train,x2_train], y_train, verbose=0)\n",
    "print('Train loss:', score[0])\n",
    "print('Train accuracy:', score[1])\n",
    "\n",
    "score = best_model.evaluate([x_valid,x2_valid], y_valid, verbose=0)\n",
    "print('Valid loss:', score[0])\n",
    "print('Valid accuracy:', score[1])\n",
    "\n",
    "score = best_model.evaluate([x_test,x2_test], y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = y_test\n",
    "y_scores = best_model.predict([x_test,x2_test])\n",
    "print(roc_auc_score(y_true, y_scores))\n",
    "\n",
    "with open(\"result_09_deep_learning_ROC.obj\", \"wb\") as f:\n",
    "    pickle.dump({\"true\":y_true,\"score\":y_scores}, f)\n",
    "\n",
    "y_true = y_train\n",
    "y_scores = best_model.predict([x_train,x2_train])\n",
    "print(roc_auc_score(y_true, y_scores))\n",
    "\n",
    "y_true = y_valid\n",
    "y_scores = best_model.predict([x_valid,x2_valid])\n",
    "print(roc_auc_score(y_true, y_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CyTOF_DL",
   "language": "python",
   "name": "cytof_dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
